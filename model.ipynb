{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG/center_2017_06_21_01_22_08_298.jpg\n",
      "Training...\n",
      "Epoch 1/3\n",
      "10704/10712 [============================>.] - ETA: 0s - loss: 0.0342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10728/10712 [==============================] - 238s - loss: 0.0342 - val_loss: 0.0244\n",
      "Epoch 2/3\n",
      "10728/10712 [==============================] - 233s - loss: 0.0300 - val_loss: 0.0230\n",
      "Epoch 3/3\n",
      "10728/10712 [==============================] - 243s - loss: 0.0272 - val_loss: 0.0207\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Lambda, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "#creating an array with all the csv lines\n",
    "lines = []\n",
    "with open(\"data\\driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "        \n",
    "#I used the udacity sample data to train my model but since that wasnt enough I had to train further and the training done on\n",
    "#my computer resulted in a different kind of line being updated in the driving_log.csv file so I used this command to edit the \n",
    "#'lines' list\n",
    "for line in lines[8037:13396]:\n",
    "    line[0] = \"IMG/\" + line[0].split(\"\\\\\")[-1]\n",
    "    line[1] = \"IMG/\" + line[1].split(\"\\\\\")[-1]\n",
    "    line[2] = \"IMG/\" + line[2].split(\"\\\\\")[-1]\n",
    "\n",
    "\n",
    "print(lines[8838][0]) \n",
    "\n",
    "#It must be noted very importantly that the first line in the reader are the column headings and must be avoided in the samples.\n",
    "train_samples, validation_samples = train_test_split(lines[1:len(lines)], test_size=0.2)\n",
    "\n",
    "batch_size = 8\n",
    "correction_factor = 0.2\n",
    "\n",
    "def generator(samples, batch_size = 16):\n",
    "    global correction_factor\n",
    "    while 1:\n",
    "        \n",
    "        \n",
    "        #no_of_batches = len(samples)/batch_size\n",
    "        shuffle(samples)\n",
    "        num_samples = (len(samples)//batch_size)*batch_size\n",
    "        for offset in range(0,num_samples, batch_size):\n",
    "            batch_sample = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            steering_angles = []\n",
    "            \n",
    "            for line in batch_sample:\n",
    "                \n",
    "                centre_path = line[0]\n",
    "                left_path = line[1]\n",
    "                right_path = line[2]\n",
    "                \n",
    "                centre_path = \".//data//IMG//\" + centre_path.split(\"/\")[-1]\n",
    "                left_path = \".//data//IMG//\" + left_path.split(\"/\")[-1]\n",
    "                right_path = \".//data//IMG//\" + right_path.split(\"/\")[-1]\n",
    "                \n",
    "#               for every line in lines I appended the centre, left and right images to the 'images' array\n",
    "#               and their corresponding steering angles along with the right corresponding steering angle\n",
    "                centre_img = mpimg.imread(centre_path)\n",
    "                left_img = mpimg.imread(left_path)\n",
    "                right_img = mpimg.imread(right_path)\n",
    "\n",
    "                images.append(centre_img)\n",
    "                images.append(left_img)\n",
    "                images.append(right_img)\n",
    "                angle = float(line[3])\n",
    "                #centre angle\n",
    "                steering_angles.append(angle)\n",
    "                #left angle\n",
    "                steering_angles.append(angle + correction_factor)\n",
    "                #right angle\n",
    "                steering_angles.append(angle - correction_factor)\n",
    "                \n",
    "            X_train = np.array(images)\n",
    "            Y_train = np.array(steering_angles)\n",
    "            yield (X_train, Y_train)\n",
    "\n",
    "\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "\n",
    "       \n",
    "print(\"Training...\")\n",
    "model = Sequential()\n",
    "#Normalizing Layer\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "#Cropping the unnecessary parts of the image\n",
    "model.add(Cropping2D(cropping = ((70,25),(0,0))))\n",
    "#Convolutional Layers\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode='valid'))\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode='valid'))\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode='valid'))\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(2, 2), border_mode='valid'))\n",
    "model.add(Activation(activation='relu'))\n",
    "#Linear Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch= (len(train_samples)//batch_size)*batch_size, validation_data=\n",
    "                    validation_generator, nb_val_samples=(len(validation_samples)//batch_size)*batch_size, nb_epoch=3)\n",
    "model.save('model.h5')\n",
    "print(\"Training Complete\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
